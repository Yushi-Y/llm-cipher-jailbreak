# llm-cipher-jailbreak

> ‚ö†Ô∏è **Project Archived** | **Status: Discontinued**

This project was an initial exploration into benchmarking Large Language Models (LLMs) on cipher transformations of harmful requests (e.g., Pig Latin) to evaluate jailbreak success rates. 

However, after similar work was published by others, I decided not to proceed with this project.

---

## üìÑ Project Overview

- **Goal:** Benchmark LLM robustness against cipher-based jailbreak attempts.
- **Idea:** Use simple text transformations (e.g., Pig Latin, letter shifting, ASCII code) to disguise harmful prompts and measure how often LLMs fail to refuse them.
- **Metric:** Jailbreak success rates under different cipher transformations.

---

## ‚ùó Project Status: Archived

- No further development will be made.
- This repository remains as a placeholder to document the initial idea.
- You're welcome to fork or refer to it for related work.
